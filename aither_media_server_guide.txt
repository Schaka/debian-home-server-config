[h1]Introduction[/h1]

[h4]Reasoning[/h4]
This is the private version of my [url=https://github.com/Schaka/media-server-guide]public guide[/url]. As such, I won't be using OpenMediaVault but instead assume you a default Debian installation. So this can be applied to both an unmanaged seedbox like [url=https://www.hetzner.com/de/sb]from Hetzner[/url]. In that case, you'd be using software RAID. Locally, you would likely use mergerfs with SnapRAID to use as many differently sized drives as you wish.

This is intended to get you into the world of securing your own media, storing it on your own drives and streaming it to your own devices. This guide is loosely based off of [url=https://flemmingss.com/a-minimal-configuration-step-by-step-guide-to-media-automation-in-unraid-using-radarr-sonarr-prowlarr-jellyfin-jellyseerr-and-qbittorrent/]Jellyfin with UnRAID[/url] which first got me into self-hosting. So big thanks to them - I liked their file structure and based mine largely on that.

It's also documentation intended for myself. Please bear that in mind - if you would have done things differently or it doesn't fit your exact usecase, please feel free to change it to your liking. If you notice any bad practises, you're welcome to let me know why it's bad and how to do it instead.

I will not go into how to make your server available publically through DynDNS and streaming remotely. I just don't think it fits in the scope of this guide.
However, if you are interested in doing that, please look into DuckDNS, port forwarding in your router and using Let's Encrypt certificates in Nginx Proxy Manager.

[h4]Disclaimer[/h4]
The idea is to use free software only with a focus on using open source software whereever possible. 
There are many options like Proxmox, Unraid or even just Ubuntu Server. I chose Debian as I feel that makes it the most easily reproducible between a hosted seedbox and a home server.
If you rent a server, you likely won't need a VPN. Disabling UDP and forcing TCP in your torrent client should be enough. If you aren't using default torrent ports, there is no reason anyone should be able to tell what you're doing.

[b]The attachment with all the files can be found here - I will probably move it to a Git repository at some point: [/b][url=https://file.io/ivG9K2wmKb22]Download link[/url]

[h1]Hardware[/h1]

[h4]Reasoning[/h4]
The way I see it, there are 2 routes to go with a low cost system before factoring in a storage solution. 
As this guide won't focus on storage solutions, it is up to you how you handle that. The hardware suggested may not be the best choice if you want a storage and media server all in one solution. It's purely intended to get you a transcoding capable media server.

If you are looking to build a NAS, homeserver or something more advanced, you may look into NAS cases from U NAS or Silverstone. They have some of the best I've found in my research.
I was personally running a SATA to eSATA adapter with an external IcyDock enclosure for a while - but YMMV.

[h4]Choices[/h4]
The cheapest way to go is likely to buy an Optiplex 3070 with an i5 8400 or i8 9400. Do not buy F processors.
The integrated Intel HD graphics are really good for transcoding if you ever need it.

Alternatively, if pricing in your area doesn't match (her3, those Optiplex SFF systems cost about 300â‚¬), you should look towards a barebones Optiplex 7020, 9020 or HP ProDesk 400 G1/G2.5.
These are all SFF systems that will take a Xeon E3 1220L v3, 1230L v3, 1240L v3 etc. They are low powered chips - but you can buy the regular ones (non-L) as well if power draw isn't a concern.
Keep in mind, that these do not have integrated graphics and you'll need to factor in the cost of a low profile used Nvidia Quadro P400 for transcoding.

As SanDisk Cruzer 2.0 USB is generally advised to keep the OS on for most solutions. Any internal SSD can then be used for storage.

[h2]Installation[/h2]
Download [url=https://www.debian.org/download]Debian[/url] and BalenaEtcher to flash it onto a USB drive. Install the system on the SanDisk Cruzer USB (or a similar one you purchased). If you are struggling, I believe there are plenty of YouTube tutorials. This assumes network is already set up and connected via Ethernet.

After installation, log into the server and type:
[code]sudo apt update
sudo apt install net-tools[/code]
You can now use [code]ifconfig[/code] to find the IP your server was assigned by your router and should then be able to access it via a different system.

[h2]Configuration[/h2]
At this point, it's probably smart to switch to SSH and remote into your server. If you're renting, it should be available already. If not, you may follows [url=https://linuxhint.com/enable-ssh-server-debian/]this tutorial[/url]. If you went with OMV after all, you can use the web GUI to set it up.

It's now time to install Docker and Portainer so it'll be easier to manage your containers. First, the setup.
[code]
sudo apt-get update
sudo apt-get install ca-certificates curl gnupg
[/code]
[code]
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg
[/code]
[code]
echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \
  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
[/code]
Now we can just use apt to install Docker Engine.
[code]
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
[/code]

[h4]User[/h4]

We'll now create the user in charge of all our media. The folders we're going to create will all be owned by that user.
[code]
groupadd -g 1000 seedbox
useradd -u 1000 -g 1000 seedbox
[/code]

[h1]Dockerizing your system[/h1]

No, we want to create our own docker network that keeps our containers isolated. Within this network, they will all be able to communicate with each other by their container names, but every port needs to be forwarded to the host explicitly, if you want to expose them. To do this, we use 
[code]docker network create htpc[/code] 
where 'htpc' is the name of our new network.
Now we [url=https://docs.portainer.io/start/install-ce/server/docker/linux]install Portainer[/url].
[code]docker run -d -p 8000:8000 -p 9443:9443 --name portainer --network=htpc --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest[/code]
You can now access it via:
[code]http://your-ip:9443/[/code] 
Try it out.


[h1]Creating your shared file structure[/h1]
We're assuming all your drives' space that isn't allocated to your operating system system can be found under the root path: '/'. If this isn't the case, you will need to adjust your file structure. All files supplied by me assume the given folder structure.  Especially the 'appdata' folder we're creating here should be backed up frequently. It contains all your configuration files. 

[code]
mkdir /appdata
mkdir /share_media
mkdir /share_media/torrents
mkdir /share_media/torrents/movies
mkdir /share_media/torrents/tv
mkdir /share_media/media
mkdir /share_media/media/movies
mkdir /share_media/media/tv
chown -R 1000:1000 /appdata
chown -R 1000:1000 /share_media
[/code]

Your folder structure should now look like this:
[code]/share_media
--- media
  |--- tv
  |--- movies
  |--- music
  |--- comics
--- torrents
  |--- tv
  |--- movies
--- usenet
  |--- tv
  |--- movies[/code]

[h1]Containers[/h1]
You can build these compose files from templates, but I'll add them all here as well. Little note regarding the mount of the '/appdata' folder. This is not strictly necessary, but I prefer putting everything the container would write, like a database, outside of the 'docker.img' itself.

[b]Note:[/b] When doing this with mergerfs, there are [url=https://github.com/trapexit/mergerfs#plex-doesnt-work-with-mergerfs]conflicts with SQLite[/url]. Refer to the guide on GitHub.

You'll now want to open Portainer at:
[code]http://your-ip:9443/#!/home[/code]
Now Live connect to the environment 'local'.
The left menu should now show Templates, Containers, Stacks, etc. A docker-compose file is called a stack in Portainer. You can click on 'Stacks' create a new stack by clicking 'Add stack', call it e.g. 'jellyfin' and then copy-paste the contents of the respective compose file which I have supplied in this thread's attachment into it. This is how you create a new container in Portainer.  You can then see it spun up in the 'Containers' tab, where you can see its assigned IP address, click another button to see its logs or even open bash or sh to execute commands from within the container.

[h3]Jellyfin[/h3]
Start with Jellyfin. You can find the compose files in the attachment. Once the container is started, you can find your installation here:
[code]http://your-ip:8096[/code]
Go through the process of adding both the movies and TV show folder. From within the container, using the interface, you can find them under '/data/media/'. You need to create one library for type movies and one for type shows.

Technically, from this point on you can place media files here and play them, if you already own a library.

[h3]Radarr[/h3]
Radarr is next. Find the compose file and use it. You can find it under:
[code]http://your-ip:7878/[/code]
Once in, go to movies and import existing movies. Choose '/data/media/movies' as per Jellyfin example above.

[h3]Sonarr[/h3]
Sonarr is next. Find the compose file and use it. You can find it under:
[code]http://your-ip:8989/[/code]
Once in, go to tv and import existing tv shows. Choose '/data/media/tv' as per Jellyfin example above.

[h3]Recyclarr - configuring both Sonarr and Radarr[/h3]
This section will give you a short overview of configurations for quality profiles in those applications. I highly recommend you read [url=https://trash-guides.info/]TRaSH Guides[/url] to understand what this is all about.

Use the recyclarr container with the respective compose.yml. I already set up a basic configuration for you, that uses Docker's container names to easily access other containers within our docker network, [i]htpc[/i]. For any further changes, consult the Recyclarr documentation.
Place the 'recyclarr.yml' file in '/appdata/recyclarr/'. [b]You need to replace the API keys with your own Sonarr and Radarr API keys in their respective application's General Settings.[/b]

You should really understand what you're doing and why. [b]If you're lazy here, you will regret it later[/b].

[h4]Instructions[/h4]

[list]
[*] Go to Settings -> Media Management and turn off Hide Advanced Settings at the top
[*] Create empty Series/Movies folder
[*] Delete empty folders
[*] Use Hardlinks instead of Copy
[*] Import Extra files (srt)
[*] Propers and Repacks (Do not Prefer)
[*] Analyse video files
[*] Set Permissions 
[*] chmod Folder 755
[*] chown Group 1000
[/list]


[h4]Sonarr naming scheme[/h4]
- Standard Episode Format [code]{Series TitleYear} - S{season:00}E{episode:00} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRangeType]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels]}{[MediaInfo VideoCodec]}{-Release Group}[/code]
- Daily Episode Format [code]{Series TitleYear} - {Air-Date} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRangeType]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels]}{[MediaInfo VideoCodec]}{-Release Group}[/code] 
- Anime Episode Format [code]{Series TitleYear} - S{season:00}E{episode:00} - {absolute:000} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRangeType]}[{MediaInfo VideoBitDepth}bit]{[MediaInfo VideoCodec]}[{Mediainfo AudioCodec} { Mediainfo AudioChannels}]{MediaInfo AudioLanguages}{-Release Group}[/code]
- Series Folder Format [code]{Series TitleYear} [imdb-{ImdbId}][/code]

[h4]Radar naming scheme[/h4]
- Standard Movie Format [code]{Movie CleanTitle} {(Release Year)} [imdbid-{ImdbId}] - {Edition Tags }{[Custom Formats]}{[Quality Full]}{[MediaInfo 3D]}{[MediaInfo VideoDynamicRangeType]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels}][{Mediainfo VideoCodec}]{-Release Group}[/code]
- Movie Folder Format [code]{Movie CleanTitle} ({Release Year}) [imdbid-{ImdbId}][/code]

[b]Note:[/b] You can change this to keep the original filename, if you think you ever need to go back and seed the original files after removing them from your client. However, this setup basically enables you to seed forever while watching that same media. So this isn't strictly necessary.

[h3]Prowlarr[/h3]
Prowlarr abstracts away all kinds of different Torrent and Usenet trackers. You give Prowlarr access to your accounts and it communicates with the trackers. Sonarr and Radarr then communicate with Prowlarr, because it pushes tracker information to them using their APIs.

Use the respective compose.yml and start your container. You'll find it under:
[code]http://your-ip:9696/[/code]
Create an account and log in.
Go to Settings -> Apps:
[list]
[*] add Radarr, in the Prowlarr server replace 'localhost' with 'prowlarr'
[*] for the Radarr server, replace replace 'localhost' with 'radarr'
[*] enter your API key as found in your Radarr Settings
[*] add Sonarr, in the Prowlarr server replace replace 'localhost' with 'prowlarr'
[*] for the Sonarr server, replacer eplace 'localhost' with 'sonarr'
[*] enter your API key as found in your Sonarr Settings
[/list]

Indexers are not explained further in this part of the guide.

[h3]Jellyseerr[/h3]
Use the respective compose.yml to start the container. You'll find it under:
[code]http://your-ip:5055/[/code]
Don't be confused by the Plex account. Click "Use your Jellyfin account" at the bottom.
[list]
[*] log in with the jellyfin account you created previously
[*] use 'http://jellyfin:8096/'
[*] the email doesn't matter
[*] click Sync Libraries, choose Movies and TV Shows and click Continue
[*] Add a Radarr server, name it Radarr and use 'radarr' as the hostname
[*] enter your API key
[*] repeat for Sonarr respectively
[/list]

This abstracts having to add shows and movies to Sonarr and Radarr manually. It'll let you curate a wishlist and shows you what's popular right now, so you'll always hear about the latest things going on in entertainment.

[h3]Bazarr[/h3]
Bazarr downloads subtitles for you, based on your shows.
Use the respective compose.yml to start the container. You'll find it under:
[code]http://your-ip:6767/[/code]

You need to add languages you want to download by going to Settings -> Languages. Create a New Profile that at least contains English.
In Settings -> Sonarr, use 'sonarr' as the host, enter your API key, test and save.
In Settings -> Radarr, use 'radarr' as the host, enter your API key, test and save.
[b]Don't forget to add subtitle providers of your choice, they are specific to your use case.[/b]

There are sooo many options here, most of which are specific to your case. I recommend looking at the TRaSH Guides again.
Note: If you have a lot of old shows that it's hard or impossible to find subtitles for, you can use [url=https://wiki.bazarr.media/Additional-Configuration/Whisper-Provider/]OpenAPI's Whisper[/url] to generate subtitles with your Nvidia GPU.

[h3]Gluetun[/h3]
Glueun is my preferred way of handling VPNs. There are many containers for torrenting and Usenet with VPNs already built in. I personally prefer having a single container that I can choose to route all my traffic through for whichever other container I choose. I can technically route 10 different clients all through the same connection here. 

It should be noted here, that if you intend to use private torrent trackers that usually have their own economy and depend on your ration, it is recommended to use a VPN with port-forwarding. I personally use AirVPN and it works just fine for my slow connection at home (250/40Mbit) but at least via OpenVPN it was very slow (about 80-100Mbit) in its upload when I tried it on my seedbox. ProtonVPN may be better - do your own research.

Gluetun requires different setup, depending on your VPN provider. Your best bet is [url=https://github.com/qdm12/gluetun-wiki]reading the wiki[/url]. While I am including a compose.yml here, it's really just an example of how to set up a VPN with port forwarding.

[b]You will need to place your [i]client.key[/i] and [i]username.cert[/i] in [i]/appdata/gluetun[/i]. Read the wiki![/b]
The example compose.yml does not contain the necessary evironment variables. The bloat would make it less readable for an easy tutorial.

[h3]qBittorrent[/h3]
The torrent client should always hide behind a VPN. Bittorrent isn't encrypted by default and even if you don't care much about anonymity, the added security is not to be neglected. Therefore I'm offering 2 compose.yml with and without a connecting to gluetun. After spinning up the container, qBittorrent is available at [i]http://your-ip:8082/[/i] to log in as [i]admin[/i] with password [i]adminadmin[/i]. You may change this later if you wish. Absolutely change this if you're hosting it and it's publically available.
To confirm that routing qbittorrent works through the VPN, you can open your 'Containers' menu in Portainer, click on '>' next to 'qbittorrent' and once the console opens, type [i]curl ifconfig.me[/i].
It will return your current IP - this should be the VPN's IP, not your own or your seedbox's. 

Do NOT use the default ports. Most VPN providers will not allow forwarding those. Additionally, everyone knows what traffic is run through those ports. A random port above 55000 is recommended.

[b]If you don't use gluetun, all configs referring to gluetun need to be replaced with qbittorrent. These are the container names.[/b]

[list]
[*] go to Settings -> Connection and change the port to whichever port-forwarded port you chose when setting up your gluetun container, you'll find it in that compose.yml
[*] Torrent Management Mode -> Automatic
[*] When Category Changed -> Relocate Torrent
[*] When Default Save Path Changed -> Relocate Affected Torrents
[*] When Category Save Path Changed -> Relocate Affected Torrents
[*] Default Save Path: [i]/data/torrents[/i]
[*] Keep incomplete torrents in [i]/data/incomplete[/i]
[*] Go to Categories on the left -> All - Right Click -> Add Category -> name it radarr with path [i]/data/torrents/movies[/i]
[*] Go to Categories on the left -> All - Right Click -> Add Category -> name it sonarr with path [i]/data/torrents/tv[/i]
[/list]

Now add the client 'qBittorrent' to both Radarr and Sonarr. 
Settings -> Download Clients -> Add Client -> qBittorrent
The host needs to be [i]gluetun[/i], the port [i]8082[/i] and the username and password as above - or whatever you changed them to.
The category needs to be either [i]radarr[/i] or [i]sonarr[/i]. They need to match the categories in the client you created above.

[h3]Indexers[/h3]
You can now add your preferred indexers and trackers to Prowlarr. It should support pretty much any available ones.

Please refer to Prowlarr's documentation if you have trouble setting uo an indexer that isn't already listed with them.
Once you've done so, you can go to System -> Tasks and manually trigger Application Indexer Sync. They should then appear in Sonarr and Radarr automatically.
If you now search for content via Sonarr and Radarr, they will scan all of your previously set up indexer and download matching results.

Obviously, here is where you'd want to set up Aither.

[h3]Cross-seed[/h3]
This step is completely optional.
Cross-seed is a great little application that automatically searches for your existing torrents on other trackers. If you're currently seeding a torrent anyway, why not make it available no every tracker you're on and build some free ratio (since you don't have to download anything) while you're at it?

All you have to do is setup another Docker container with a static IP and have qbittorrent notify your cross-seed container when a torrent finishes. 
A quick explanation regarding the [i]BT_backup[/i] directory that [i]needs[/i] to be mapped. This contains qbittorrent's backup [i].torrent[/i] files.
Mapping of the [i]cross-seeds[/i] directory is NOT strictly necessary. We are assigning the static IP, because our torrent client is behind a VPN and can't access cross-seed using the container name.

You need to place [i]config.js[/i] in your [i]/appdata/cross-seed[/i] directory. 
The following values need to be adjusted:
[list]
[*] qbittorrentUrl (if you do not use gluetun, replace with qbittorrent in the URL)
[*] torznab
[/list]

You will find the torznab URLs for your trackers in Prowlarr. Open your "Indexers" page - you'll see an "RSS" button at the right of every tracker in the table.
This is the URL you need. You don't need the [i]&extended=1&t=search[/i] part.

Now all that's left to do is make qbittorrent notify cross-seed of finished torrents so it can look for matches across all your trackers.
Open qbitorrent's web GUI, open the settings, go to the "Downloads" section and scroll all the way to the bottom. Find "Run external program on torrent finished", enable it and set it to:
[i]curl -XPOST http://172.18.0.115:2468/api/webhook --data-urlencode "name=%N"[/i]. [b]Note:[/b] The IP here (specifically .115) is the one we set as our static IP in the cross-seed Docker container. Through Gluetun, it's not possible to access it via http://cross-seed. If you do not use Gluetun, you can replace the IP with 'cross-seed' here.

[h3]qbit_manage[/h3]
This step is completely optional. It gives you a bit more control over your cross-seeded torrents, keeps your torrent folder clean.
As an example - when Sonarr upgrades an episode or a season, the old torrent loses its hardlink as it becomes irrelevant - you now own a better quality copy. The old copy still remains seeded in your torrent folder, but Sonarr will NOT clean up once it hits the seeding requirements. It will get "stuck" there forever. qbit_manage can recognize this and clean up for you.
It also allows you to set specific limits for each and every tracker. 

In sonarr and radarr, you'll want to go to Settings -> Download Clients, activate Advanced Settings at the top left and select your qBittorrent client.
Here, scroll down. While your category should remain [i]sonarr[/i], your post-import-category should be [i]tv[/i]. For Radarr, it should be [i]radarr[/i] and [i]movies[/i],

For installation, you need to place [i]config.yml[/i] in your [i]/appdata/qbit_manage[/i] directory.
The following properties need to be changed:
[list]
[*] qbit [host, user, pass] at the top (if you do not use Gluetun, replace with qbittorrent in the URL).
[*] directory - if you use any additional ones to what's in this guide
[*] cat - if you use any additional ones to what's in this guide
[*] cat_change - according to the 2 above points
[*] tracker, add any trackers you want to manage that aren't already on this list
[*] share_limits - you need to move tracker tags around and into the categories you wish to keep them in
[/list]

[b]Note:[/b] With this setup, any upgraded episode in Sonarr will have no hardlink, get tagged noHL in qbittorrent and then seeded for one month at most. If you wish to change this, you need to adjust the share_limit section for noHL.

Additionally, I have chosen to cross-seed only according to my tracker rules. If you want to cross-seed indefinitely or until the file is cleared up in general, you need to move the share_limit section for cross-seed further up in priority. 
Also be aware that only torrents without hardlinks are automatically cleaned up by qbit_manage. If you want other categories to be automatically cleaned up, set the [i]cleanup[/i] property from false to true in the share_limit section. 

Refer to the [url=https://github.com/StuffAnThings/qbit_manage/wiki]full documentation[/url] for anything else.

[h3]L4G-Upload-Assistant[/h3]
This is a great automated tool for uploading to your favorite trackers (if they're supported). It automatically takes screenshots and analyzes the files via MediaInfo. All the data is saved in the mounted [i]/tmp[/i] directory where you can find the [i].torrent[/i] file and upload everything manually if needed.
However, you can also set up the connection to your indexers and upload directly. I personally recommend you do that. You'll to need move both files in the l4g-upload-assistant directory to your [i]/appdata/l4g-upload-assistant[/i] - see below.

[code]
# Create directory for this container's files
mkdir /appdata/l4g-upload-assistant
# move config.py and run.sh into the folder above, tool of your choice
chown -R 1000:1000 /appdata/l4g-upload-assistant
chmod +x /appdata/l4g-upload-assistant/run.sh
[/code]

You can now call the following code, where [i]<path>[/i] is your torrent under [i]/share_media/torrents[/i]. 
[code]
# <path> could be "Reservation.Dogs.S03E05.House.Made.of.Bongs.2160p.HULU.WEB-DL.DDP5.1.H.265-NTb.mkv" MTV
# <tracker> could be MTV, AITHER, BLU, BHD, etc - you can find them in the config file
./appdata/l4g-upload-assistant/run.sh "<path>" "<tracker>"
[/code]

The script will automatically recreate the Docker container, run L4G-Upload-Assistant and then call to docker logs, so that you can see what's going on.


[h1]Post-Install[/h1]
First of all, congratulations. You've managed to make it past the hardest part. It's all smooth sailing from here on out. You should now have enough knowledge and understanding to run a second instance of Sonarr running on a different port just for Anime or run separate instances for 1080p and 4k, if you have plenty of storage but don't want to waste power on transcoding.
My personal opinion is that 4k TO 1080p/720p transcodes using hardware acceleration are cheaper than separate libraries.

[h1]Home-server only[/h1]
Everything past this point only applies if you're using a server at home. Your rented Jellyfin server won't have an Nvidia GPU and setting up mDNS is not possible. There are tutorials you can look up on how to use domains and park certain containers behind a specific domain. My seedbox doesn't expose any container's ports outside of the 'htpc' docker network and all access to any application running on it, including Portainer is purely through Nginx-Proxy-Manager.

[h2]Making sure transcoding works[/h2]
Most info taken from [url=https://jellyfin.org/docs/general/administration/hardware-acceleration/nvidia/]Jellyfin's documentation[/url].
The reason we picked up the P400 is because it's a very small, cheap card of the Pascal generation and thus supports HEVC 10 bit encoding. 

Add [i]contrib[/i] and [i]non-free[/i] to your repositories inside the [i]/etc/apt/sources.list[/i] file. You can use vi or nano to edit this file. Follow the instructions here to install your [url=https://forum.openmediavault.org/index.php?thread/38013-howto-nvidia-hardware-transcoding-on-omv-5-in-a-plex-docker-container/&postID=313378#post313378]Nvidia drivers[/url] if you went with the Quadro P400.

Install proprietary packages to support transcoding via [i]sudo apt update && sudo apt install -y libnvcuvid1 libnvidia-encode1[/i].
Then call [i]nvidia-smi[/i] to confirm your GPU is detected and running. If you have Secure Boot enabled in your BIOS, see the note about signing packages [url=https://wiki.debian.org/NvidiaGraphicsDrivers#Version_470.129.06]here[/url].

You should be able to just install the entire CUDA toolkit, if you think you'll need anything else via [i]sudo apt-get install nvidia-cuda-toolkit[/i]. Keep in mind, this is pretty large. If you don't know whether you need it, don't jump the gun.

After following all the instructions to install Nvidia drivers, run [i]nvidia-smi[/i] to confirm the GPU is working. 
Add admin to the video user group: [i]sudo usermod -aG video admin[/i].

Use [i]the jellyfin-nvidia-compose.yml[/i], restart the container with it, then run [i]docker exec -it jellyfin ldconfig && sudo systemctl restart docker[/i]. Open your Jellyfin interface, go to Administrator -> Dashboard -> Playback and enable transcoding. It's best you follow the Jellyfine documentation, but the general gist is to enable Nvidia NVENC and every codec besides AV1. Allow encoding to HEVC as well.

**Note:* If you are using the [i]linuxserver/jellyfin[/i] image instead of the [i]jellyfin/jellyfin[/i] image, you need to add [i]NVIDIA_VISIBLE_DEVICES=all[/i] under environment in your compose.yml that the following may be required underneath 'container_name'.
[code]
    group_add:
      - '109' #render
      - '44' #video
[/code]
 
You can confirm transcoding works by forcing a lower quality via the settings when playing a video or playing something unsupported for DirectPlay. While a video is playing, going to Settings -> Playback Info will open a great debug menu.

[h4]Improving H264[/h4]
I highly recommend you enable HEVC transcoding in Jellyfin's playback settings and find yourself a Jellyfin client (like Jellyfin Media Player) that supports preferring to transcode to HEVC. Nvidia's H264 is pretty terrible. If you won't transcode many streams simulatenously, it may be an option to play with the transcode settings in Jellyfin at force a higher quality at the expense of more GPU resources. You need to find what works best for you.

If you know for a fact you will have transcode to H264 a lot, something like a 10th gen i3 based media server with Intel QuickSync will result in much better quality. I personally only use the Nvidia card as a worst case scenario fallback and will play all H264 natively whenever possible.

[h4]Making HEVC/h265/x265 work[/h4]
If you want support for HEVC transcoding in Chrome out of the box, [url=https://github.com/jellyfin/jellyfin-web/pull/4041]there's this PR[/url]. You could merge this and supply your own Docker image.

Jellyfin Media Player [url=https://github.com/jellyfin/jellyfin-media-player/issues/319]has an option[/url] to transcode to HEVC over h264.

People have reported, that [url=https://github.com/jellyfin/jellyfin/issues/9458#issuecomment-1465300270]using Kodi[/url] as a client or Jellyfin for Kodi preferred HEVC and will force your server to transcode to HEVC over h264, if transcoding happens.

If you're looking to primarily watch in your browser, it's worth merging the above PR yourself. However, you'd have to build the jellyfin-web project yourself and place the compiled frontend files on your server, so that you can use Docker to map it like so [i]/appdata/jellyfin/web/:/jellyfin/jellyfin-web[/i] and overwrite the supplied contents of the docker image.

[h3]DNS setup[/h3]
Many people here will likely to fire up pihole or Adguard Home. These are valuable options, but in my experience they introduce another issue. If you run your DNS server on your media server and it ever goes down, you have a single point of failure. Your entire network won't be able to resolve any names. It'll become essentially unusable. If you already have DNS running on another server in your network or your router supports it, say through OpenWRT or OPNSense, just set up a few entries and skip to the explanation for Nginx Proxy Manager.

[h4]mDNS[/h4]
To solve the issue(s) described above, we're going to set up mDNS. Every call to a name suffixed in [i].local[/i] is automatically sent to the entire network and your server can choose to respond to it or not. So your media server itself will be responsible for listening to a name like [i]media-pc.local[/i].

If it's not already installed, install avahi-daemon via [i]apt install avahi-daemon[/i] and [i]apt install avahi-utils[/i].
To confirm this works, you should now be able to access your web GUI via [i]http://media-pc.local[/i] assuming your host name is set to media-pc during installation or in the web GUI under Network -> Hostname.

We can now use [i]avahi-publish[/i] to add an another alias, like sonarr, radarr, jellyfin, etc.
You can confirm this works, by executing
[code]/bin/bash -c "/usr/bin/avahi-publish -a -R sonarr.local  $(avahi-resolve -4 -n media-pc.local | cut -f 2)"[/code] 
and then accessing your server via sonarr.local in the browser. Press Ctrl+C in your terminal to cancel it again.

Create a new file called [i]/etc/systemd/system/aliases.service[/i]. The content should be as follows:
[code]
[Unit]
Description=Publish aliases for local media server
Wants=network-online.target
After=network-online.target
BindsTo=sys-subsystem-net-devices-enp0s31f6.device
Requires=avahi-daemon.service

[Service]
Type=forking
ExecStart=/srv/mergerfs/config/appdata/aliases.sh

[Install]
WantedBy=multi-user.target
[/code]
[b]Note: The device under BindsTo, called [i]enp0s31f6[/i], needs to be changed to the device listed under Network -> Interfaces in your web GUI[/b]. This will execute a file called aliases.sh whenever your network starts/restarts. It will then automatically publish all the available aliases you set in that file. You can find the aliases.sh file that serves as a template here and place it in [i]/appdata[/i]. Make sure to make the file executable via [i]chmod +x aliases.sh[/i].

Now do [i]systemctl daemon reload[/i], [i]systemctl start aliases[/i] and [i]systemctl enable aliases[/i]. The latter will set the script to auto start. You should now be able to access your server via [i]tv.local[/i], [i]sonarr.local[/i], etc.

[h4]Reverse Proxy[/h4]
We're going to use nginx as a reverse proxy. If you're already familiar with that, set it up as you wish. I will, however, use Nginx Proxy Manager for an easy GUI.

Create a new docker container with respective compose.yml. You should then be able to access its web GUI via [i]http://your-ip:81/[/i].
Login with the default credentials and make an account.
[code]
Email: admin@example.com
Password: changeme
[/code]

You can now add a proxy host. Add domain [i]media-pc.local[/i] and add port forward 180. For the forward host, you can add [i]media-pc.local[/i] again. This will forward port 80 to 180. After saving, you should be able to access your server via [i]http://media-pc.local[/i] again.

You may now add entries for all the other aliases.
[list]
[*] sonarr.local forward to host sonarr with port 8989
[*] radarr.local forward to host radarr with port 7878
[*] prowlarr.local forward to host prowlarr with port 9696
[*] bazarr.local forward to host bazarr with port 6767
[*] qbittorrent.local forward to gluetun with port 8082
[*] catalog.local forward to host jellyseerr with port 5055
[*] tv.local forward to host jellyfin with port 8096
[/list]

All your services should now be reachable via their respective [i]name.local[/i]. 
[b]Note:[/b] Because nginx is accessing these services through the 'htpc' docker network, you could now remove port forwarding for individual containers, if you only want them reachable through HTTP behind your reverse proxy.


[h3]Honorable mentions and other things you might want to look into[/h3]
- [url=https://github.com/Schaka/rarrnomore]Rarrnomore[/url] - lets you avoid grabbing rar'd releases
- [url=https://github.com/Unpackerr/unpackerr]Unpackerr[/url] - lets you unrar releases automatically (if you have enough space to seed the rar and keep the content)
- [url=https://www.audiobookshelf.org/]Audiobookshelf[/url] - similar to Jellyfin, but for audiobooks
- [url=https://autobrr.com/]autobrr[/url] - lets you connect to your trackers' IRC to automatically grab new releases rather than waiting for RSS updates
- [url=https://komga.org/]Komga[/url] - similar to Jellyfin, for reading comic books and mangas
- [url=https://github.com/benphelps/homepage]homepage[/url] - lets you create a dashboard for all your services
- [url=https://lidarr.audio/]Lidarr[/url] - Sonarr/Radarr alternative for music
- [url=https://github.com/Unmanic/unmanic]Unmanic[/url] - lets you transcode all your media; download REMUXES and transcode them to your own liking